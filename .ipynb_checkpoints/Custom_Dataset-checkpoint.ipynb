{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42863b58-9ee9-429e-839e-0f0b1c7fe340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import get_rays\n",
    "from rendering import rendering\n",
    "from model import Voxels, Nerf\n",
    "from ml_helpers import training\n",
    "\n",
    "from skimage.measure import marching_cubes\n",
    "import trimesh\n",
    "import trimesh.smoothing\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00a9542d-e971-4872-9687-68927a4693b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:  2.5.1\n",
      "device:  mps\n"
     ]
    }
   ],
   "source": [
    "print(\"torch version: \", torch.__version__)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else: \n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219a4ebc-5826-4ae7-aa6f-4c458c63cb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/_x9hjmys03x5gnbfl70ry2sr0000gn/T/ipykernel_5722/3184953490.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('model_nerf_mps').to(device)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('model_nerf_mps').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06570af1-8917-4031-8299-68ae1ea176b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Surface level must be within volume data range.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 98\u001b[0m\n\u001b[1;32m     95\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnerf_mesh.ply\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Can also use .obj format\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Extract and save the mesh\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m mesh \u001b[38;5;241m=\u001b[39m \u001b[43msave_colored_mesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 84\u001b[0m, in \u001b[0;36msave_colored_mesh\u001b[0;34m(nerf_model, output_path, resolution, device)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msave_colored_mesh\u001b[39m(nerf_model, output_path, resolution\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    Extract and save a colored mesh from a NeRF model.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m        device: Torch device to use\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     mesh \u001b[38;5;241m=\u001b[39m \u001b[43mextract_mesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnerf_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# Optional mesh cleanup\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     mesh \u001b[38;5;241m=\u001b[39m mesh\u001b[38;5;241m.\u001b[39mprocess(validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[10], line 42\u001b[0m, in \u001b[0;36mextract_mesh\u001b[0;34m(nerf_model, resolution, threshold, bbox_min, bbox_max, device)\u001b[0m\n\u001b[1;32m     39\u001b[0m         density_volume\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[i:i\u001b[38;5;241m+\u001b[39mchunk_size] \u001b[38;5;241m=\u001b[39m chunk_densities\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Extract mesh using marching cubes\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m vertices, faces, normals, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmarching_cubes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdensity_volume\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspacing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox_max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox_max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox_max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mresolution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Adjust vertices to match bbox\u001b[39;00m\n\u001b[1;32m     51\u001b[0m vertices \u001b[38;5;241m=\u001b[39m vertices \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39marray(bbox_min)\n",
      "File \u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/skimage/measure/_marching_cubes_lewiner.py:139\u001b[0m, in \u001b[0;36mmarching_cubes\u001b[0;34m(volume, level, spacing, gradient_direction, step_size, allow_degenerate, method, mask)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlewiner\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod should be either \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlewiner\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlorensen\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_marching_cubes_lewiner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvolume\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspacing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_direction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_degenerate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_classic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_classic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/newenv/lib/python3.9/site-packages/skimage/measure/_marching_cubes_lewiner.py:180\u001b[0m, in \u001b[0;36m_marching_cubes_lewiner\u001b[0;34m(volume, level, spacing, gradient_direction, step_size, allow_degenerate, use_classic, mask)\u001b[0m\n\u001b[1;32m    178\u001b[0m     level \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(level)\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;241m<\u001b[39m volume\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;129;01mor\u001b[39;00m level \u001b[38;5;241m>\u001b[39m volume\u001b[38;5;241m.\u001b[39mmax():\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurface level must be within volume data range.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# spacing\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(spacing) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Surface level must be within volume data range."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from skimage.measure import marching_cubes\n",
    "import trimesh\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def extract_mesh(nerf_model, resolution=256, threshold=50.0, bbox_min=[-1.5, -1.5, -1.5], \n",
    "                bbox_max=[1.5, 1.5, 1.5], device=torch.device(\"cpu\")):\n",
    "    \"\"\"\n",
    "    Extract a colored mesh from a trained NeRF model.\n",
    "    \n",
    "    Args:\n",
    "        nerf_model: Trained NeRF model\n",
    "        resolution: Grid resolution for marching cubes\n",
    "        threshold: Density threshold for surface extraction\n",
    "        bbox_min: Minimum corner of bounding box\n",
    "        bbox_max: Maximum corner of bounding box\n",
    "        device: Torch device to use\n",
    "    \n",
    "    Returns:\n",
    "        trimesh.Trimesh: Colored mesh\n",
    "    \"\"\"\n",
    "    # Create grid of points\n",
    "    x = torch.linspace(bbox_min[0], bbox_max[0], resolution)\n",
    "    y = torch.linspace(bbox_min[1], bbox_max[1], resolution)\n",
    "    z = torch.linspace(bbox_min[2], bbox_max[2], resolution)\n",
    "    xx, yy, zz = torch.meshgrid(x, y, z, indexing='ij')\n",
    "    points = torch.stack([xx, yy, zz], dim=-1).to(device)\n",
    "    \n",
    "    # Create density volume\n",
    "    density_volume = torch.zeros((resolution, resolution, resolution))\n",
    "    chunk_size = 512 * 512  # Process in chunks to avoid OOM\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, points.numel() // 3, chunk_size):\n",
    "            chunk_points = points.reshape(-1, 3)[i:i+chunk_size]\n",
    "            # Assume model returns (rgb, sigma) tuple\n",
    "            _, chunk_densities = nerf_model(chunk_points, torch.zeros_like(chunk_points))\n",
    "            density_volume.reshape(-1)[i:i+chunk_size] = chunk_densities.cpu()\n",
    "    \n",
    "    # Extract mesh using marching cubes\n",
    "    vertices, faces, normals, _ = marching_cubes(\n",
    "        density_volume.numpy(),\n",
    "        threshold,\n",
    "        spacing=((bbox_max[0] - bbox_min[0])/resolution,\n",
    "                (bbox_max[1] - bbox_min[1])/resolution,\n",
    "                (bbox_max[2] - bbox_min[2])/resolution)\n",
    "    )\n",
    "    \n",
    "    # Adjust vertices to match bbox\n",
    "    vertices = vertices + np.array(bbox_min)\n",
    "    \n",
    "    # Sample colors at vertex positions\n",
    "    vertex_colors = torch.zeros((len(vertices), 3))\n",
    "    vertices_tensor = torch.tensor(vertices, dtype=torch.float32).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(vertices), chunk_size):\n",
    "            chunk_vertices = vertices_tensor[i:i+chunk_size]\n",
    "            # Assume model returns (rgb, sigma) tuple\n",
    "            chunk_colors, _ = nerf_model(chunk_vertices, torch.zeros_like(chunk_vertices))\n",
    "            vertex_colors[i:i+chunk_size] = chunk_colors.cpu()\n",
    "    \n",
    "    # Create mesh with vertex colors\n",
    "    mesh = trimesh.Trimesh(\n",
    "        vertices=vertices,\n",
    "        faces=faces,\n",
    "        vertex_colors=(vertex_colors.numpy() * 255).astype(np.uint8),\n",
    "        vertex_normals=normals\n",
    "    )\n",
    "    \n",
    "    return mesh\n",
    "\n",
    "def save_colored_mesh(nerf_model, output_path, resolution=128, device=torch.device(\"cpu\")):\n",
    "    \"\"\"\n",
    "    Extract and save a colored mesh from a NeRF model.\n",
    "    \n",
    "    Args:\n",
    "        nerf_model: Trained NeRF model\n",
    "        output_path: Path to save the mesh (should end in .ply or .obj)\n",
    "        resolution: Resolution for marching cubes\n",
    "        device: Torch device to use\n",
    "    \"\"\"\n",
    "    mesh = extract_mesh(nerf_model, resolution=resolution, device=device)\n",
    "    \n",
    "    # Optional mesh cleanup\n",
    "    mesh = mesh.process(validate=True)\n",
    "    \n",
    "    # Save the mesh\n",
    "    mesh.export(output_path)\n",
    "    return mesh\n",
    "\n",
    "# After loading your model\n",
    "resolution = 500  # Increase for better quality, decrease if you run into memory issues\n",
    "output_path = \"nerf_mesh.ply\"  # Can also use .obj format\n",
    "\n",
    "# Extract and save the mesh\n",
    "mesh = save_colored_mesh(model, output_path, resolution=resolution, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28036793-5290-4c96-babb-5ac2fc0b1c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:newenv] *",
   "language": "python",
   "name": "conda-env-newenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
