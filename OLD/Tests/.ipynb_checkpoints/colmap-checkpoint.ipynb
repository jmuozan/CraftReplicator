{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "257860de-71ad-4386-88bd-fc945e3bc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import get_rays\n",
    "from rendering import rendering\n",
    "from model import Voxels, Nerf\n",
    "from ml_helpers import training\n",
    "\n",
    "from skimage.measure import marching_cubes\n",
    "import trimesh\n",
    "import trimesh.smoothing\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0edee44f-d2ec-445c-82fe-4ec3556989f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:  2.5.1\n",
      "device:  mps\n"
     ]
    }
   ],
   "source": [
    "print(\"torch version: \", torch.__version__)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else: \n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c2e4d77-8270-42b8-8479-5b406e87d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import quaternion  # You'll need to install numpy-quaternion package\n",
    "\n",
    "def read_cameras(path):\n",
    "    \"\"\"Read COLMAP cameras.txt and convert to intrinsic matrices\"\"\"\n",
    "    cameras = {}\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        if line[0] == '#' or len(line.strip()) == 0:\n",
    "            continue\n",
    "        \n",
    "        data = line.strip().split()\n",
    "        camera_id = int(data[0])\n",
    "        # SIMPLE_RADIAL format: f, cx, cy, k\n",
    "        if data[1] == 'SIMPLE_RADIAL':\n",
    "            f = float(data[4])\n",
    "            cx = float(data[5])\n",
    "            cy = float(data[6])\n",
    "            \n",
    "            # Create 4x4 intrinsic matrix\n",
    "            K = np.array([\n",
    "                [f, 0, cx, 0],\n",
    "                [0, f, cy, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 0, 0, 1]\n",
    "            ], dtype=np.float32)\n",
    "            \n",
    "            cameras[camera_id] = K\n",
    "            \n",
    "    return cameras\n",
    "\n",
    "def read_images(path):\n",
    "    \"\"\"Read COLMAP images.txt and convert quaternions to transformation matrices\"\"\"\n",
    "    images = {}\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        if lines[i][0] == '#' or len(lines[i].strip()) == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "            \n",
    "        # First line contains pose info\n",
    "        data = lines[i].strip().split()\n",
    "        image_id = int(data[0])\n",
    "        qw, qx, qy, qz = map(float, data[1:5])\n",
    "        tx, ty, tz = map(float, data[5:8])\n",
    "        camera_id = int(data[8])\n",
    "        \n",
    "        # Convert quaternion to rotation matrix\n",
    "        q = np.quaternion(qw, qx, qy, qz)\n",
    "        R = quaternion.as_rotation_matrix(q)\n",
    "        \n",
    "        # Create 4x4 transformation matrix\n",
    "        T = np.eye(4, dtype=np.float32)\n",
    "        T[:3, :3] = R\n",
    "        T[:3, 3] = [tx, ty, tz]\n",
    "        \n",
    "        images[image_id] = {'transform': T, 'camera_id': camera_id}\n",
    "        \n",
    "        # Skip second line (2D points)\n",
    "        i += 2\n",
    "        \n",
    "    return images\n",
    "\n",
    "def save_matrix(matrix, output_path):\n",
    "    \"\"\"Save 4x4 matrix to txt file in row-major order\"\"\"\n",
    "    np.savetxt(output_path, matrix.reshape(-1), fmt='%.16f')\n",
    "\n",
    "def convert_colmap_to_matrices(colmap_dir, output_dir):\n",
    "    \"\"\"Convert COLMAP output to individual matrix files\"\"\"\n",
    "    colmap_dir = Path(colmap_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Read camera and image data\n",
    "    cameras = read_cameras(colmap_dir / 'cameras.txt')\n",
    "    images = read_images(colmap_dir / 'images.txt')\n",
    "    \n",
    "    # Save matrices\n",
    "    for image_id, image_data in images.items():\n",
    "        # Save camera intrinsics\n",
    "        camera_id = image_data['camera_id']\n",
    "        if camera_id in cameras:\n",
    "            intrinsics_path = output_dir / f'intrinsics_{image_id:03d}.txt'\n",
    "            save_matrix(cameras[camera_id], intrinsics_path)\n",
    "        \n",
    "        # Save camera pose\n",
    "        pose_path = output_dir / f'pose_{image_id:03d}.txt'\n",
    "        save_matrix(image_data['transform'], pose_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Example usage\n",
    "    colmap_dir = 'fox/colmap'  # Directory containing cameras.txt and images.txt\n",
    "    output_dir = 'fox/colmap/matrices'  # Output directory for matrix files\n",
    "    convert_colmap_to_matrices(colmap_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a89754-555f-4388-80af-986806e70bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import imageio.v2 as imageio\n",
    "from typing import Dict, Tuple\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def read_cameras(path: str) -> Dict:\n",
    "    cameras = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line[0] == \"#\": continue\n",
    "            data = line.strip().split()\n",
    "            camera_id = int(data[0])\n",
    "            cameras[camera_id] = {\n",
    "                \"model\": data[1],\n",
    "                \"width\": int(data[2]),\n",
    "                \"height\": int(data[3]),\n",
    "                \"params\": np.array(data[4:], dtype=np.float64)\n",
    "            }\n",
    "    return cameras\n",
    "\n",
    "def read_images(path: str) -> Dict:\n",
    "    images = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for i in range(0, len(lines), 2):\n",
    "        if lines[i][0] == \"#\": continue\n",
    "        data = lines[i].split()\n",
    "        points_data = lines[i + 1].split()\n",
    "        \n",
    "        image_id = int(data[0])\n",
    "        images[image_id] = {\n",
    "            \"qvec\": np.array(data[1:5], dtype=float),\n",
    "            \"tvec\": np.array(data[5:8], dtype=float),\n",
    "            \"camera_id\": int(data[8]),\n",
    "            \"name\": data[9],\n",
    "            \"xys\": np.array([(float(points_data[j]), float(points_data[j+1])) \n",
    "                           for j in range(0, len(points_data), 3)]),\n",
    "            \"point3D_ids\": np.array([int(points_data[j+2]) \n",
    "                                   for j in range(0, len(points_data), 3)])\n",
    "        }\n",
    "    return images\n",
    "\n",
    "def qvec2rotmat(qvec: np.ndarray) -> np.ndarray:\n",
    "    return np.array([\n",
    "        [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
    "         2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2]],\n",
    "        [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
    "        [2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
    "         2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]])\n",
    "\n",
    "def generate_rays(camera: Dict, image_data: Dict, img: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    # Keep original dimensions\n",
    "    H, W = img.shape[:2]\n",
    "    f = camera['params'][0]\n",
    "        \n",
    "    if img.shape[2] == 4:\n",
    "        img = img[..., :3] * img[..., -1:] + (1 - img[..., -1:])\n",
    "    \n",
    "    R = qvec2rotmat(image_data['qvec'])\n",
    "    t = image_data['tvec']\n",
    "    C = -R.T @ t\n",
    "    \n",
    "    u, v = np.meshgrid(np.arange(W), np.arange(H))\n",
    "    dirs = np.stack([(u - W/2), -(v - H/2), -np.ones_like(u) * f], axis=-1)\n",
    "    dirs = (R.T @ dirs.reshape(-1, 3).T).T\n",
    "    dirs = dirs / np.linalg.norm(dirs, axis=-1, keepdims=True)\n",
    "    \n",
    "    rays_o = np.broadcast_to(C, dirs.shape)\n",
    "    rays_d = dirs\n",
    "    target_px_values = img.reshape(-1, 3)\n",
    "    \n",
    "    return rays_o, rays_d, target_px_values\n",
    "\n",
    "def get_rays(datapath: str, mode: str = 'train') -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    colmap_dir = os.path.join(datapath, 'colmap')\n",
    "    imgs_dir = os.path.join(datapath, 'imgs')\n",
    "    \n",
    "    cameras = read_cameras(os.path.join(colmap_dir, 'cameras.txt'))\n",
    "    images = read_images(os.path.join(colmap_dir, 'images.txt'))\n",
    "    \n",
    "    # Get a sample image to determine dimensions\n",
    "    sample_img = imageio.imread(os.path.join(imgs_dir, list(images.values())[0]['name']))\n",
    "    H, W = sample_img.shape[:2]\n",
    "    \n",
    "    image_list = sorted(images.items(), key=lambda x: x[1]['name'])\n",
    "    split_idx = int(len(image_list) * 0.9)\n",
    "    selected_images = image_list[:split_idx] if mode == 'train' else image_list[split_idx:]\n",
    "    \n",
    "    rays_o = []\n",
    "    rays_d = []\n",
    "    target_px_values = []\n",
    "    \n",
    "    for image_id, image_data in selected_images:\n",
    "        img_path = os.path.join(imgs_dir, image_data['name'])\n",
    "        img = imageio.imread(img_path).astype(np.float32) / 255.0\n",
    "        \n",
    "        # Ensure consistent dimensions\n",
    "        if img.shape[:2] != (H, W):\n",
    "            from skimage.transform import resize\n",
    "            img = resize(img, (H, W, 3), anti_aliasing=True)\n",
    "        \n",
    "        camera = cameras[image_data['camera_id']]\n",
    "        ro, rd, rgb = generate_rays(camera, image_data, img)\n",
    "        \n",
    "        rays_o.append(ro)\n",
    "        rays_d.append(rd)\n",
    "        target_px_values.append(rgb)\n",
    "    \n",
    "    # Stack and reshape\n",
    "    rays_o = np.stack(rays_o)\n",
    "    rays_d = np.stack(rays_d)\n",
    "    target_px_values = np.stack(target_px_values)\n",
    "    \n",
    "    n_images = len(selected_images)\n",
    "    logger.info(f\"Number of images: {n_images}, Image dimensions: {H}x{W}\")\n",
    "    \n",
    "    return (rays_o.reshape(n_images, H, W, 3),\n",
    "            rays_d.reshape(n_images, H, W, 3),\n",
    "            target_px_values.reshape(n_images, H, W, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28303b8d-0fc6-43eb-9cb3-8e2f2255fe48",
   "metadata": {},
   "source": [
    "# move matrices and rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e175b060-5a98-4d2c-9941-7d3c03095f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been organized successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def organize_files(source_dir, test_dir, train_dir, test_count=10):\n",
    "    \"\"\"\n",
    "    Organize matrix files into test and train directories with proper subdirectories.\n",
    "    \n",
    "    Args:\n",
    "        source_dir: Path to source directory containing matrix files\n",
    "        test_dir: Path to test directory\n",
    "        train_dir: Path to train directory\n",
    "        test_count: Number of files to move to test directory\n",
    "    \"\"\"\n",
    "    # Create required directories\n",
    "    for base_dir in [test_dir, train_dir]:\n",
    "        for subdir in ['intrinsics', 'pose']:\n",
    "            os.makedirs(os.path.join(base_dir, subdir), exist_ok=True)\n",
    "    \n",
    "    # Get list of all files\n",
    "    source_path = Path(source_dir)\n",
    "    intrinsics_files = sorted([f for f in source_path.glob('intrinsics_*.txt')])\n",
    "    pose_files = sorted([f for f in source_path.glob('pose_*.txt')])\n",
    "    \n",
    "    # Move files to test directory\n",
    "    for i in range(min(test_count, len(intrinsics_files))):\n",
    "        # Move intrinsics files\n",
    "        shutil.copy2(\n",
    "            intrinsics_files[i],\n",
    "            os.path.join(test_dir, 'intrinsics', intrinsics_files[i].name)\n",
    "        )\n",
    "        # Move pose files\n",
    "        shutil.copy2(\n",
    "            pose_files[i],\n",
    "            os.path.join(test_dir, 'pose', pose_files[i].name)\n",
    "        )\n",
    "    \n",
    "    # Move remaining files to train directory\n",
    "    for i in range(test_count, len(intrinsics_files)):\n",
    "        # Move intrinsics files\n",
    "        shutil.copy2(\n",
    "            intrinsics_files[i],\n",
    "            os.path.join(train_dir, 'intrinsics', intrinsics_files[i].name)\n",
    "        )\n",
    "        # Move pose files\n",
    "        shutil.copy2(\n",
    "            pose_files[i],\n",
    "            os.path.join(train_dir, 'pose', pose_files[i].name)\n",
    "        )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Define paths\n",
    "    source_dir = 'fox/colmap/matrices'\n",
    "    test_dir = 'fox/test'\n",
    "    train_dir = 'fox/train'\n",
    "    \n",
    "    # Organize files\n",
    "    organize_files(source_dir, test_dir, train_dir, test_count=10)\n",
    "    print(\"Files have been organized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a0314e-3375-4dcf-839b-38e39f3eb54c",
   "metadata": {},
   "source": [
    "# rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e7270f8-c2b7-47ec-b56a-f0fd7041267a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed intrinsics_001.txt to test_1.txt in intrinsics\n",
      "Renamed intrinsics_002.txt to test_2.txt in intrinsics\n",
      "Renamed intrinsics_003.txt to test_3.txt in intrinsics\n",
      "Renamed intrinsics_004.txt to test_4.txt in intrinsics\n",
      "Renamed intrinsics_005.txt to test_5.txt in intrinsics\n",
      "Renamed intrinsics_006.txt to test_6.txt in intrinsics\n",
      "Renamed intrinsics_007.txt to test_7.txt in intrinsics\n",
      "Renamed intrinsics_009.txt to test_8.txt in intrinsics\n",
      "Renamed intrinsics_010.txt to test_9.txt in intrinsics\n",
      "Renamed intrinsics_011.txt to test_10.txt in intrinsics\n",
      "Renamed pose_001.txt to test_1.txt in pose\n",
      "Renamed pose_002.txt to test_2.txt in pose\n",
      "Renamed pose_003.txt to test_3.txt in pose\n",
      "Renamed pose_004.txt to test_4.txt in pose\n",
      "Renamed pose_005.txt to test_5.txt in pose\n",
      "Renamed pose_006.txt to test_6.txt in pose\n",
      "Renamed pose_007.txt to test_7.txt in pose\n",
      "Renamed pose_009.txt to test_8.txt in pose\n",
      "Renamed pose_010.txt to test_9.txt in pose\n",
      "Renamed pose_011.txt to test_10.txt in pose\n",
      "Renamed intrinsics_012.txt to train_1.txt in intrinsics\n",
      "Renamed intrinsics_013.txt to train_2.txt in intrinsics\n",
      "Renamed intrinsics_014.txt to train_3.txt in intrinsics\n",
      "Renamed intrinsics_015.txt to train_4.txt in intrinsics\n",
      "Renamed intrinsics_016.txt to train_5.txt in intrinsics\n",
      "Renamed intrinsics_017.txt to train_6.txt in intrinsics\n",
      "Renamed intrinsics_018.txt to train_7.txt in intrinsics\n",
      "Renamed intrinsics_019.txt to train_8.txt in intrinsics\n",
      "Renamed intrinsics_020.txt to train_9.txt in intrinsics\n",
      "Renamed intrinsics_021.txt to train_10.txt in intrinsics\n",
      "Renamed intrinsics_022.txt to train_11.txt in intrinsics\n",
      "Renamed intrinsics_023.txt to train_12.txt in intrinsics\n",
      "Renamed intrinsics_024.txt to train_13.txt in intrinsics\n",
      "Renamed intrinsics_025.txt to train_14.txt in intrinsics\n",
      "Renamed intrinsics_026.txt to train_15.txt in intrinsics\n",
      "Renamed intrinsics_027.txt to train_16.txt in intrinsics\n",
      "Renamed intrinsics_028.txt to train_17.txt in intrinsics\n",
      "Renamed intrinsics_029.txt to train_18.txt in intrinsics\n",
      "Renamed intrinsics_030.txt to train_19.txt in intrinsics\n",
      "Renamed intrinsics_031.txt to train_20.txt in intrinsics\n",
      "Renamed intrinsics_032.txt to train_21.txt in intrinsics\n",
      "Renamed intrinsics_033.txt to train_22.txt in intrinsics\n",
      "Renamed intrinsics_034.txt to train_23.txt in intrinsics\n",
      "Renamed intrinsics_035.txt to train_24.txt in intrinsics\n",
      "Renamed intrinsics_036.txt to train_25.txt in intrinsics\n",
      "Renamed intrinsics_037.txt to train_26.txt in intrinsics\n",
      "Renamed intrinsics_038.txt to train_27.txt in intrinsics\n",
      "Renamed intrinsics_039.txt to train_28.txt in intrinsics\n",
      "Renamed intrinsics_040.txt to train_29.txt in intrinsics\n",
      "Renamed intrinsics_041.txt to train_30.txt in intrinsics\n",
      "Renamed intrinsics_042.txt to train_31.txt in intrinsics\n",
      "Renamed intrinsics_043.txt to train_32.txt in intrinsics\n",
      "Renamed intrinsics_044.txt to train_33.txt in intrinsics\n",
      "Renamed intrinsics_045.txt to train_34.txt in intrinsics\n",
      "Renamed intrinsics_046.txt to train_35.txt in intrinsics\n",
      "Renamed intrinsics_047.txt to train_36.txt in intrinsics\n",
      "Renamed intrinsics_048.txt to train_37.txt in intrinsics\n",
      "Renamed intrinsics_049.txt to train_38.txt in intrinsics\n",
      "Renamed intrinsics_050.txt to train_39.txt in intrinsics\n",
      "Renamed intrinsics_051.txt to train_40.txt in intrinsics\n",
      "Renamed intrinsics_052.txt to train_41.txt in intrinsics\n",
      "Renamed intrinsics_053.txt to train_42.txt in intrinsics\n",
      "Renamed intrinsics_054.txt to train_43.txt in intrinsics\n",
      "Renamed intrinsics_055.txt to train_44.txt in intrinsics\n",
      "Renamed intrinsics_056.txt to train_45.txt in intrinsics\n",
      "Renamed intrinsics_057.txt to train_46.txt in intrinsics\n",
      "Renamed intrinsics_058.txt to train_47.txt in intrinsics\n",
      "Renamed intrinsics_059.txt to train_48.txt in intrinsics\n",
      "Renamed intrinsics_060.txt to train_49.txt in intrinsics\n",
      "Renamed intrinsics_061.txt to train_50.txt in intrinsics\n",
      "Renamed intrinsics_062.txt to train_51.txt in intrinsics\n",
      "Renamed intrinsics_063.txt to train_52.txt in intrinsics\n",
      "Renamed intrinsics_064.txt to train_53.txt in intrinsics\n",
      "Renamed intrinsics_065.txt to train_54.txt in intrinsics\n",
      "Renamed intrinsics_066.txt to train_55.txt in intrinsics\n",
      "Renamed intrinsics_067.txt to train_56.txt in intrinsics\n",
      "Renamed intrinsics_068.txt to train_57.txt in intrinsics\n",
      "Renamed intrinsics_069.txt to train_58.txt in intrinsics\n",
      "Renamed intrinsics_070.txt to train_59.txt in intrinsics\n",
      "Renamed intrinsics_071.txt to train_60.txt in intrinsics\n",
      "Renamed intrinsics_072.txt to train_61.txt in intrinsics\n",
      "Renamed intrinsics_073.txt to train_62.txt in intrinsics\n",
      "Renamed intrinsics_074.txt to train_63.txt in intrinsics\n",
      "Renamed intrinsics_075.txt to train_64.txt in intrinsics\n",
      "Renamed intrinsics_076.txt to train_65.txt in intrinsics\n",
      "Renamed intrinsics_077.txt to train_66.txt in intrinsics\n",
      "Renamed intrinsics_078.txt to train_67.txt in intrinsics\n",
      "Renamed intrinsics_079.txt to train_68.txt in intrinsics\n",
      "Renamed intrinsics_080.txt to train_69.txt in intrinsics\n",
      "Renamed intrinsics_081.txt to train_70.txt in intrinsics\n",
      "Renamed intrinsics_082.txt to train_71.txt in intrinsics\n",
      "Renamed intrinsics_083.txt to train_72.txt in intrinsics\n",
      "Renamed intrinsics_084.txt to train_73.txt in intrinsics\n",
      "Renamed intrinsics_085.txt to train_74.txt in intrinsics\n",
      "Renamed intrinsics_086.txt to train_75.txt in intrinsics\n",
      "Renamed intrinsics_087.txt to train_76.txt in intrinsics\n",
      "Renamed intrinsics_088.txt to train_77.txt in intrinsics\n",
      "Renamed intrinsics_089.txt to train_78.txt in intrinsics\n",
      "Renamed intrinsics_090.txt to train_79.txt in intrinsics\n",
      "Renamed intrinsics_091.txt to train_80.txt in intrinsics\n",
      "Renamed intrinsics_092.txt to train_81.txt in intrinsics\n",
      "Renamed intrinsics_093.txt to train_82.txt in intrinsics\n",
      "Renamed intrinsics_094.txt to train_83.txt in intrinsics\n",
      "Renamed intrinsics_095.txt to train_84.txt in intrinsics\n",
      "Renamed intrinsics_096.txt to train_85.txt in intrinsics\n",
      "Renamed intrinsics_097.txt to train_86.txt in intrinsics\n",
      "Renamed intrinsics_098.txt to train_87.txt in intrinsics\n",
      "Renamed intrinsics_099.txt to train_88.txt in intrinsics\n",
      "Renamed intrinsics_100.txt to train_89.txt in intrinsics\n",
      "Renamed pose_012.txt to train_1.txt in pose\n",
      "Renamed pose_013.txt to train_2.txt in pose\n",
      "Renamed pose_014.txt to train_3.txt in pose\n",
      "Renamed pose_015.txt to train_4.txt in pose\n",
      "Renamed pose_016.txt to train_5.txt in pose\n",
      "Renamed pose_017.txt to train_6.txt in pose\n",
      "Renamed pose_018.txt to train_7.txt in pose\n",
      "Renamed pose_019.txt to train_8.txt in pose\n",
      "Renamed pose_020.txt to train_9.txt in pose\n",
      "Renamed pose_021.txt to train_10.txt in pose\n",
      "Renamed pose_022.txt to train_11.txt in pose\n",
      "Renamed pose_023.txt to train_12.txt in pose\n",
      "Renamed pose_024.txt to train_13.txt in pose\n",
      "Renamed pose_025.txt to train_14.txt in pose\n",
      "Renamed pose_026.txt to train_15.txt in pose\n",
      "Renamed pose_027.txt to train_16.txt in pose\n",
      "Renamed pose_028.txt to train_17.txt in pose\n",
      "Renamed pose_029.txt to train_18.txt in pose\n",
      "Renamed pose_030.txt to train_19.txt in pose\n",
      "Renamed pose_031.txt to train_20.txt in pose\n",
      "Renamed pose_032.txt to train_21.txt in pose\n",
      "Renamed pose_033.txt to train_22.txt in pose\n",
      "Renamed pose_034.txt to train_23.txt in pose\n",
      "Renamed pose_035.txt to train_24.txt in pose\n",
      "Renamed pose_036.txt to train_25.txt in pose\n",
      "Renamed pose_037.txt to train_26.txt in pose\n",
      "Renamed pose_038.txt to train_27.txt in pose\n",
      "Renamed pose_039.txt to train_28.txt in pose\n",
      "Renamed pose_040.txt to train_29.txt in pose\n",
      "Renamed pose_041.txt to train_30.txt in pose\n",
      "Renamed pose_042.txt to train_31.txt in pose\n",
      "Renamed pose_043.txt to train_32.txt in pose\n",
      "Renamed pose_044.txt to train_33.txt in pose\n",
      "Renamed pose_045.txt to train_34.txt in pose\n",
      "Renamed pose_046.txt to train_35.txt in pose\n",
      "Renamed pose_047.txt to train_36.txt in pose\n",
      "Renamed pose_048.txt to train_37.txt in pose\n",
      "Renamed pose_049.txt to train_38.txt in pose\n",
      "Renamed pose_050.txt to train_39.txt in pose\n",
      "Renamed pose_051.txt to train_40.txt in pose\n",
      "Renamed pose_052.txt to train_41.txt in pose\n",
      "Renamed pose_053.txt to train_42.txt in pose\n",
      "Renamed pose_054.txt to train_43.txt in pose\n",
      "Renamed pose_055.txt to train_44.txt in pose\n",
      "Renamed pose_056.txt to train_45.txt in pose\n",
      "Renamed pose_057.txt to train_46.txt in pose\n",
      "Renamed pose_058.txt to train_47.txt in pose\n",
      "Renamed pose_059.txt to train_48.txt in pose\n",
      "Renamed pose_060.txt to train_49.txt in pose\n",
      "Renamed pose_061.txt to train_50.txt in pose\n",
      "Renamed pose_062.txt to train_51.txt in pose\n",
      "Renamed pose_063.txt to train_52.txt in pose\n",
      "Renamed pose_064.txt to train_53.txt in pose\n",
      "Renamed pose_065.txt to train_54.txt in pose\n",
      "Renamed pose_066.txt to train_55.txt in pose\n",
      "Renamed pose_067.txt to train_56.txt in pose\n",
      "Renamed pose_068.txt to train_57.txt in pose\n",
      "Renamed pose_069.txt to train_58.txt in pose\n",
      "Renamed pose_070.txt to train_59.txt in pose\n",
      "Renamed pose_071.txt to train_60.txt in pose\n",
      "Renamed pose_072.txt to train_61.txt in pose\n",
      "Renamed pose_073.txt to train_62.txt in pose\n",
      "Renamed pose_074.txt to train_63.txt in pose\n",
      "Renamed pose_075.txt to train_64.txt in pose\n",
      "Renamed pose_076.txt to train_65.txt in pose\n",
      "Renamed pose_077.txt to train_66.txt in pose\n",
      "Renamed pose_078.txt to train_67.txt in pose\n",
      "Renamed pose_079.txt to train_68.txt in pose\n",
      "Renamed pose_080.txt to train_69.txt in pose\n",
      "Renamed pose_081.txt to train_70.txt in pose\n",
      "Renamed pose_082.txt to train_71.txt in pose\n",
      "Renamed pose_083.txt to train_72.txt in pose\n",
      "Renamed pose_084.txt to train_73.txt in pose\n",
      "Renamed pose_085.txt to train_74.txt in pose\n",
      "Renamed pose_086.txt to train_75.txt in pose\n",
      "Renamed pose_087.txt to train_76.txt in pose\n",
      "Renamed pose_088.txt to train_77.txt in pose\n",
      "Renamed pose_089.txt to train_78.txt in pose\n",
      "Renamed pose_090.txt to train_79.txt in pose\n",
      "Renamed pose_091.txt to train_80.txt in pose\n",
      "Renamed pose_092.txt to train_81.txt in pose\n",
      "Renamed pose_093.txt to train_82.txt in pose\n",
      "Renamed pose_094.txt to train_83.txt in pose\n",
      "Renamed pose_095.txt to train_84.txt in pose\n",
      "Renamed pose_096.txt to train_85.txt in pose\n",
      "Renamed pose_097.txt to train_86.txt in pose\n",
      "Renamed pose_098.txt to train_87.txt in pose\n",
      "Renamed pose_099.txt to train_88.txt in pose\n",
      "Renamed pose_100.txt to train_89.txt in pose\n",
      "Files have been renamed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def rename_files(base_dir):\n",
    "    \"\"\"\n",
    "    Rename files in test and train directories to follow the pattern:\n",
    "    test_X.txt or train_X.txt where X is a sequential number\n",
    "    \n",
    "    Args:\n",
    "        base_dir: Base directory containing test and train folders\n",
    "    \"\"\"\n",
    "    # Process both test and train directories\n",
    "    for dir_type in ['test', 'train']:\n",
    "        dir_path = Path(base_dir) / dir_type\n",
    "        \n",
    "        # Process both intrinsics and pose subdirectories\n",
    "        for subdir in ['intrinsics', 'pose']:\n",
    "            subdir_path = dir_path / subdir\n",
    "            \n",
    "            # Get all txt files in the directory\n",
    "            files = sorted(list(subdir_path.glob('*.txt')))\n",
    "            \n",
    "            # Rename files\n",
    "            for i, file_path in enumerate(files, 1):\n",
    "                new_name = f\"{dir_type}_{i}.txt\"\n",
    "                new_path = subdir_path / new_name\n",
    "                \n",
    "                # Rename the file\n",
    "                os.rename(file_path, new_path)\n",
    "                print(f\"Renamed {file_path.name} to {new_name} in {subdir}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Define base directory\n",
    "    base_dir = 'fox'\n",
    "    \n",
    "    # Rename files\n",
    "    rename_files(base_dir)\n",
    "    print(\"Files have been renamed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5922e325-8976-4a36-88aa-908cbe4d3953",
   "metadata": {},
   "source": [
    "# Camera / Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e62ab8-9524-48b6-a646-01b27c9a3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "o, d, target_px_values = get_rays('fox', mode='train')\n",
    "\n",
    "# Regular dataloader\n",
    "dataloader = DataLoader(torch.cat((\n",
    "    torch.from_numpy(o).reshape(-1, 3).type(torch.float),\n",
    "    torch.from_numpy(d).reshape(-1, 3).type(torch.float),\n",
    "    torch.from_numpy(target_px_values).reshape(-1, 3).type(torch.float)), dim=1),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Warmup dataloader with cropped center region\n",
    "dataloader_warmup = DataLoader(torch.cat((\n",
    "    torch.from_numpy(o).reshape(89, 400, 400, 3)[:, 100:300, 100:300, :].reshape(-1, 3).type(torch.float),\n",
    "    torch.from_numpy(d).reshape(89, 400, 400, 3)[:, 100:300, 100:300, :].reshape(-1, 3).type(torch.float),\n",
    "    torch.from_numpy(target_px_values).reshape(89, 400, 400, 3)[:, 100:300, 100:300, :].reshape(-1, 3).type(torch.float)), dim=1),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Test data\n",
    "test_o, test_d, test_target_px_values = get_rays('fox', mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcc6284-ff38-4a9d-a914-7cd8ff9163fb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edd96eec-e258-469d-8781-da1dc2bd1ca6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader_warmup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m     12\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mMultiStepLR(optimizer, milestones\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m], gamma\u001b[38;5;241m=\u001b[39mgamma)\n\u001b[0;32m---> 16\u001b[0m training_loss \u001b[38;5;241m=\u001b[39m training(model, optimizer, scheduler, tn, tf, nb_bins, \u001b[38;5;241m1\u001b[39m, \u001b[43mdataloader_warmup\u001b[49m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(training_loss)\n\u001b[1;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader_warmup' is not defined"
     ]
    }
   ],
   "source": [
    "device = device\n",
    "\n",
    "tn = 8.\n",
    "tf = 12.\n",
    "nb_epochs = 1 #15 30\n",
    "lr =  1e-3 # 1e-3 5e-4\n",
    "gamma = .5 #0.5 0.7 \n",
    "nb_bins = 100 #100 256\n",
    "\n",
    "model = Nerf(hidden_dim=256).to(device) #Nerf(hidden_dim=128).to(device) \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10], gamma=gamma)\n",
    "\n",
    "\n",
    "\n",
    "training_loss = training(model, optimizer, scheduler, tn, tf, nb_bins, 1, dataloader_warmup, device=device)\n",
    "plt.plot(training_loss)\n",
    "plt.show()\n",
    "training_loss = training(model, optimizer, scheduler, tn, tf, nb_bins, nb_epochs, dataloader, device=device)\n",
    "plt.plot(training_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2ceae-86b6-4d6d-aafe-ac3627807f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_nerf_colmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be732b56-fa20-4a47-8b2a-f918c1ea5d7a",
   "metadata": {},
   "source": [
    "# Mesh extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6764d29-c8b9-417f-ad7f-a2aa42554303",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model_nerf_colmap').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e0f3d9-71c0-4149-93a3-a16ff6263e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from skimage.measure import marching_cubes\n",
    "import trimesh\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def analyze_density_field(density_volume):\n",
    "    \"\"\"Analyze the density field to help choose a good threshold.\"\"\"\n",
    "    min_density = float(density_volume.min())\n",
    "    max_density = float(density_volume.max())\n",
    "    mean_density = float(density_volume.mean())\n",
    "    std_density = float(density_volume.std())\n",
    "    \n",
    "    print(f\"Density field statistics:\")\n",
    "    print(f\"Min: {min_density:.6f}\")\n",
    "    print(f\"Max: {max_density:.6f}\")\n",
    "    print(f\"Mean: {mean_density:.6f}\")\n",
    "    print(f\"Std: {std_density:.6f}\")\n",
    "    \n",
    "    # Suggest threshold as mean + 1 std deviation\n",
    "    suggested_threshold = mean_density + std_density\n",
    "    return suggested_threshold\n",
    "\n",
    "def extract_mesh(nerf_model, resolution=128, threshold=None, bbox_min=[-1.5, -1.5, -1.5], \n",
    "                bbox_max=[1.5, 1.5, 1.5], device=torch.device(\"cpu\")):\n",
    "    \"\"\"\n",
    "    Extract a colored mesh from a trained NeRF model.\n",
    "    \n",
    "    Args:\n",
    "        nerf_model: Trained NeRF model\n",
    "        resolution: Grid resolution for marching cubes\n",
    "        threshold: Density threshold for surface extraction (if None, will be auto-determined)\n",
    "        bbox_min: Minimum corner of bounding box\n",
    "        bbox_max: Maximum corner of bounding box\n",
    "        device: Torch device to use\n",
    "    \n",
    "    Returns:\n",
    "        trimesh.Trimesh: Colored mesh\n",
    "    \"\"\"\n",
    "    print(f\"Creating density volume with resolution {resolution}...\")\n",
    "    \n",
    "    # Create grid of points\n",
    "    x = torch.linspace(bbox_min[0], bbox_max[0], resolution)\n",
    "    y = torch.linspace(bbox_min[1], bbox_max[1], resolution)\n",
    "    z = torch.linspace(bbox_min[2], bbox_max[2], resolution)\n",
    "    xx, yy, zz = torch.meshgrid(x, y, z, indexing='ij')\n",
    "    points = torch.stack([xx, yy, zz], dim=-1).to(device)\n",
    "    \n",
    "    # Create density volume\n",
    "    density_volume = torch.zeros((resolution, resolution, resolution))\n",
    "    chunk_size = 512 * 512  # Process in chunks to avoid OOM\n",
    "    \n",
    "    print(\"Sampling density field...\")\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, points.numel() // 3, chunk_size):\n",
    "            chunk_points = points.reshape(-1, 3)[i:i+chunk_size]\n",
    "            # Assume model returns (rgb, sigma) tuple\n",
    "            _, chunk_densities = nerf_model(chunk_points, torch.zeros_like(chunk_points))\n",
    "            density_volume.reshape(-1)[i:i+chunk_size] = chunk_densities.cpu()\n",
    "    \n",
    "    # Auto-determine threshold if not provided\n",
    "    if threshold is None:\n",
    "        threshold = analyze_density_field(density_volume)\n",
    "        print(f\"Auto-determined threshold: {threshold:.6f}\")\n",
    "    \n",
    "    print(f\"Extracting mesh with threshold {threshold}...\")\n",
    "    \n",
    "    try:\n",
    "        # Extract mesh using marching cubes\n",
    "        vertices, faces, normals, _ = marching_cubes(\n",
    "            density_volume.numpy(),\n",
    "            threshold,\n",
    "            spacing=((bbox_max[0] - bbox_min[0])/resolution,\n",
    "                    (bbox_max[1] - bbox_min[1])/resolution,\n",
    "                    (bbox_max[2] - bbox_min[2])/resolution)\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(\"Error during marching cubes:\")\n",
    "        print(e)\n",
    "        print(\"\\nTry adjusting the threshold based on the density statistics above.\")\n",
    "        raise\n",
    "    \n",
    "    print(f\"Mesh extracted with {len(vertices)} vertices and {len(faces)} faces\")\n",
    "    \n",
    "    # Adjust vertices to match bbox\n",
    "    vertices = vertices + np.array(bbox_min)\n",
    "    \n",
    "    # Sample colors at vertex positions\n",
    "    vertex_colors = torch.zeros((len(vertices), 3))\n",
    "    vertices_tensor = torch.tensor(vertices, dtype=torch.float32).to(device)\n",
    "    \n",
    "    print(\"Sampling colors...\")\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(vertices), chunk_size):\n",
    "            chunk_vertices = vertices_tensor[i:i+chunk_size]\n",
    "            # Assume model returns (rgb, sigma) tuple\n",
    "            chunk_colors, _ = nerf_model(chunk_vertices, torch.zeros_like(chunk_vertices))\n",
    "            vertex_colors[i:i+chunk_size] = chunk_colors.cpu()\n",
    "    \n",
    "    # Create mesh with vertex colors\n",
    "    mesh = trimesh.Trimesh(\n",
    "        vertices=vertices,\n",
    "        faces=faces,\n",
    "        vertex_colors=(vertex_colors.numpy() * 255).astype(np.uint8),\n",
    "        vertex_normals=normals\n",
    "    )\n",
    "    \n",
    "    return mesh\n",
    "\n",
    "def save_colored_mesh(nerf_model, output_path, resolution=256, threshold=None, device=torch.device(\"cpu\")):\n",
    "    \"\"\"\n",
    "    Extract and save a colored mesh from a NeRF model.\n",
    "    \n",
    "    Args:\n",
    "        nerf_model: Trained NeRF model\n",
    "        output_path: Path to save the mesh (should end in .ply or .obj)\n",
    "        resolution: Resolution for marching cubes\n",
    "        threshold: Density threshold (if None, will be auto-determined)\n",
    "        device: Torch device to use\n",
    "    \"\"\"\n",
    "    mesh = extract_mesh(nerf_model, resolution=resolution, threshold=threshold, device=device)\n",
    "    \n",
    "    print(\"Processing mesh...\")\n",
    "    # Optional mesh cleanup\n",
    "    mesh = mesh.process(validate=True)\n",
    "    \n",
    "    print(f\"Saving mesh to {output_path}...\")\n",
    "    # Save the mesh\n",
    "    mesh.export(output_path)\n",
    "    return mesh\n",
    "\n",
    "# After loading your model\n",
    "resolution = 700  # Increase for better quality, decrease if you run into memory issues\n",
    "output_path = \"nerf_mesh.obj\"  # Can also use .obj format\n",
    "\n",
    "# Extract and save the mesh\n",
    "mesh = save_colored_mesh(model, output_path, resolution=resolution, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b528771-b4d7-4285-8fd3-d15842b3f8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94e15e1-1f6b-4372-9ee0-22a25cea75c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d3a25-9d9d-4248-a210-9876f24a5f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2956aa-8e87-44fc-94d9-8b3fd4c54569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d91e1c2-ce41-4977-a3f9-944067a3af11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b0840-5978-4b21-b1b0-07dc04daa80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c99cb50-6a3a-482f-9e91-493359805a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ece44-7ef1-4086-ac35-0054a0d37394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Pymcubes\n",
    "#!pip install trimesh\n",
    "#!pip install -U scikit-image\n",
    "#!pip install genesis-world  # Requires Python >=3.9;\n",
    "#!pip uninstall genesis-world\n",
    "#!conda install -c anaconda trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1340391-1311-4703-87db-6b37b442b4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac8b37-99bb-41b7-92e3-71ef9d9f9e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c97ed5-c343-4e17-957a-137d1c1a1acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de10ac4-4564-416c-81f5-0c6d22286d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:newenv] *",
   "language": "python",
   "name": "conda-env-newenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
