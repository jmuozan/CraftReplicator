import torch
import numpy as np
import os
import imageio
import json
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader


def get_rays_from_transforms(datapath, mode='train'):
    """
    Load camera rays from a transforms.json file generated by colmap2nerf.py
    
    Args:
        datapath (str): Path to the dataset folder containing transforms.json
        mode (str): 'train' or 'test' to filter images
        
    Returns:
        rays_o (np.ndarray): Ray origins, shape (N, H*W, 3)
        rays_d (np.ndarray): Ray directions, shape (N, H*W, 3)
        target_px_values (np.ndarray): Target pixel values, shape (N, H*W, 3)
    """
    # Look for transforms.json in the current directory or in the datapath
    transforms_path = 'transforms.json'  # First try current directory
    if not os.path.exists(transforms_path):
        transforms_path = os.path.join(datapath, 'transforms.json')
    
    # Load the transforms.json file
    with open(transforms_path, 'r') as f:
        transforms = json.load(f)
    
    # Filter frames based on mode (train or test)
    frames = [f for f in transforms['frames'] if mode in f['file_path']]
    N = len(frames)
    
    if N == 0:
        raise ValueError(f"No frames found for mode '{mode}'. Check your transforms.json file.")
    
    # Get image dimensions from the JSON file
    H = int(transforms['h'])
    W = int(transforms['w'])
    
    # Extract camera parameters
    focal_x = transforms['fl_x']
    focal_y = transforms['fl_y'] 
    cx = transforms['cx']
    cy = transforms['cy']
    
    # Initialize arrays - explicitly use float32
    rays_o = np.zeros((N, H*W, 3), dtype=np.float32)
    rays_d = np.zeros((N, H*W, 3), dtype=np.float32)
    images = []
    
    for i, frame in enumerate(frames):
        # Get transform matrix (camera-to-world)
        c2w = np.array(frame['transform_matrix'], dtype=np.float32)
        
        # Load image - handle either paths starting with ./ or not
        file_path = frame['file_path']
        if file_path.startswith('./'):
            file_path = file_path[2:]  # Remove ./ prefix
        
        img_path = file_path
        
        try:
            img = imageio.imread(img_path).astype(np.float32) / 255.0
        except FileNotFoundError:
            # Try looking in a few other places
            alternative_paths = [
                os.path.join(datapath, file_path),
                os.path.join(datapath, 'imgs', os.path.basename(file_path)),
                os.path.join('imgs', os.path.basename(file_path))
            ]
            
            for alt_path in alternative_paths:
                try:
                    img = imageio.imread(alt_path).astype(np.float32) / 255.0
                    print(f"Found image at {alt_path}")
                    break
                except FileNotFoundError:
                    continue
            else:
                raise FileNotFoundError(f"Could not find image at {file_path} or any alternative locations")
        
        # Handle RGBA images
        if img.shape[-1] == 4:
            img = img[..., :3] * img[..., -1:] + (1 - img[..., -1:])
        
        images.append(img[None, ...])
        
        # Generate rays
        u, v = np.meshgrid(np.arange(W), np.arange(H))
        # Convert pixel coordinates to camera space - using correct focal length scaling
        dirs = np.stack([(u - cx) / focal_x, -(v - cy) / focal_y, -np.ones_like(u)], axis=-1).astype(np.float32)
        # Rotate rays to world space
        dirs = (c2w[:3, :3] @ dirs.reshape(-1, 3, 1)).squeeze(-1)
        # Normalize ray directions
        dirs = dirs / np.linalg.norm(dirs, axis=-1, keepdims=True)
        
        rays_d[i] = dirs
        rays_o[i] = np.broadcast_to(c2w[:3, 3], (H*W, 3))
    
    # Concatenate images and reshape
    images = np.concatenate(images)
    target_px_values = images.reshape((N, H*W, 3))
    
    return rays_o, rays_d, target_px_values


def get_rays(datapath, mode='train'):
    """
    Main function to get rays and target pixel values.
    Automatically detects and uses transforms.json if it exists.
    
    Args:
        datapath (str): Path to the dataset folder
        mode (str): 'train' or 'test'
        
    Returns:
        rays_o (np.ndarray): Ray origins
        rays_d (np.ndarray): Ray directions
        target_px_values (np.ndarray): Target pixel values
    """
    # Always use transforms.json in this case
    return get_rays_from_transforms(datapath, mode)