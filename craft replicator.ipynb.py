{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Position Estimation from Photogrammetry Images\n",
    "\n",
    "This notebook estimates camera positions from a set of images using PyTorch3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Install PyTorch3D if needed\n",
    "if 'pytorch3d' not in sys.modules:\n",
    "    !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n",
    "\n",
    "from pytorch3d.transforms.so3 import so3_exp_map, so3_relative_angle\n",
    "from pytorch3d.renderer.cameras import SfMPerspectiveCameras\n",
    "from pytorch3d.features import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_images(image_dir):\n",
    "    \"\"\"Load all images from directory and convert to tensors.\"\"\"\n",
    "    image_paths = list(Path(image_dir).glob('*.jpg')) + list(Path(image_dir).glob('*.png'))\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        img_tensor = torch.from_numpy(np.array(img)).float().permute(2, 0, 1) / 255.0\n",
    "        images.append(F.interpolate(img_tensor.unsqueeze(0), size=(224, 224)))\n",
    "    return torch.cat(images, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def compute_relative_transforms(features):\n",
    "    \"\"\"Compute relative camera transforms between all image pairs.\"\"\"\n",
    "    N = features.shape[0]\n",
    "    edges = []\n",
    "    R_relative = []\n",
    "    T_relative = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            # Compute feature matching and essential matrix\n",
    "            feat_i = features[i].reshape(-1, features.shape[-1])\n",
    "            feat_j = features[j].reshape(-1, features.shape[-1])\n",
    "            \n",
    "            # Simplified relative pose estimation\n",
    "            sim = torch.mm(feat_i, feat_j.t())\n",
    "            if sim.max() > 0.7:  # Threshold for good matches\n",
    "                edges.append([i, j])\n",
    "                # Initialize with identity rotation and random translation\n",
    "                R_relative.append(torch.eye(3))\n",
    "                T_relative.append(torch.randn(3))\n",
    "    \n",
    "    return torch.stack(R_relative), torch.stack(T_relative), torch.tensor(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def optimize_camera_positions(R_relative, T_relative, relative_edges, n_cameras, device='cpu'):\n",
    "    \"\"\"Optimize absolute camera positions given relative transforms.\"\"\"\n",
    "    # Initialize absolute camera parameters\n",
    "    log_R_absolute = torch.randn(n_cameras, 3, device=device)\n",
    "    T_absolute = torch.randn(n_cameras, 3, device=device)\n",
    "    \n",
    "    # First camera at origin\n",
    "    log_R_absolute[0, :] = 0.\n",
    "    T_absolute[0, :] = 0.\n",
    "    \n",
    "    log_R_absolute.requires_grad = True\n",
    "    T_absolute.requires_grad = True\n",
    "    \n",
    "    # Create relative cameras\n",
    "    cameras_relative = SfMPerspectiveCameras(\n",
    "        R=R_relative.to(device),\n",
    "        T=T_relative.to(device),\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Optimization\n",
    "    optimizer = torch.optim.Adam([log_R_absolute, T_absolute], lr=0.01)\n",
    "    \n",
    "    for iteration in range(1000):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Convert log rotations to matrices\n",
    "        R_absolute = so3_exp_map(log_R_absolute)\n",
    "        \n",
    "        # Create absolute cameras\n",
    "        cameras_absolute = SfMPerspectiveCameras(\n",
    "            R=R_absolute,\n",
    "            T=T_absolute,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Compute relative cameras from absolute positions\n",
    "        trans_i = cameras_absolute.get_world_to_view_transform()[relative_edges[:, 0]]\n",
    "        trans_j = cameras_absolute.get_world_to_view_transform()[relative_edges[:, 1]]\n",
    "        trans_rel = trans_i.inverse().compose(trans_j)\n",
    "        \n",
    "        # Compute loss\n",
    "        matrix_rel = trans_rel.get_matrix()\n",
    "        R_composed = matrix_rel[:, :3, :3]\n",
    "        T_composed = matrix_rel[:, 3, :3]\n",
    "        \n",
    "        R_loss = (1. - so3_relative_angle(R_composed, cameras_relative.R, cos_angle=True)).mean()\n",
    "        T_loss = ((T_composed - cameras_relative.T)**2).sum(1).mean()\n",
    "        \n",
    "        loss = R_loss + T_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            print(f'Iteration {iteration}, Loss: {loss.item():.6f}')\n",
    "    \n",
    "    return R_absolute.detach(), T_absolute.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Main execution\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load and process images\n",
    "images = load_images('media')\n",
    "images = images.to(device)\n",
    "\n",
    "# Extract features\n",
    "with torch.no_grad():\n",
    "    features = extract_features(images)\n",
    "\n",
    "# Compute relative transforms\n",
    "R_relative, T_relative, relative_edges = compute_relative_transforms(features)\n",
    "\n",
    "# Optimize camera positions\n",
    "R_absolute, T_absolute = optimize_camera_positions(\n",
    "    R_relative, \n",
    "    T_relative, \n",
    "    relative_edges, \n",
    "    n_cameras=len(images),\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Print results\n",
    "for i in range(len(images)):\n",
    "    print(f'\\nCamera {i}:')\n",
    "    print(f'Rotation:\\n{R_absolute[i]}')\n",
    "    print(f'Translation: {T_absolute[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 }
}